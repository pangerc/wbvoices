# Creative Pipeline Redesign: ElevenLabs V3 & Strategy Pattern Architecture

_October 2025_

## Overview

A comprehensive redesign of the voice generation creative pipeline, triggered by the discovery of ElevenLabs V3 capabilities and culminating in a Strategy Pattern refactor that eliminated 230 lines of switch/case complexity while adding powerful new features.

### The Journey

```
Investigation: "Which ElevenLabs model are we using?"
    ‚Üì
Discovery: V3 offers 70+ languages, emotional tags, 3000 char limit
    ‚Üì
Testing: Polish dialogue with emotional tags - GOLD!
    ‚Üì
Architecture Review: Found 230 lines of switch/case chaos + missing gender field
    ‚Üì
Refactor: Strategy Pattern implementation with provider-specific strategies
    ‚Üì
Bug Fixes: Speed parameter restored, gender field added
    ‚Üì
Feature: User-facing pacing control (üê¢ Slow | üê∞ Fast)
    ‚Üì
Result: Clean architecture + better voice quality + new capabilities
```

## The Architecture Problem

### What We Found

**File**: `src/app/api/ai/generate/route.ts` (original 443 lines)

**Problems Identified**:

1. **Switch/Case Chaos** (lines 67-296): 230 lines of provider-specific prompt construction
2. **Missing Gender Field**: Critical metadata not sent to LLM for dialog casting
3. **Code Duplication**: Similar prompt logic repeated for each provider
4. **Hard to Extend**: Adding new providers required 200+ lines of code
5. **Error-Prone**: Easy to forget provider-specific requirements

**Example of the Old Code**:
```typescript
// 230 lines of switch/case statements
switch (provider) {
  case "elevenlabs":
    styleInstructions = `For ElevenLabs, use the following emotional dimensions...
    // 50+ lines of provider-specific instructions
    `;
    break;
  case "openai":
    styleInstructions = `For OpenAI TTS, provide detailed "voiceInstructions"...
    // 40+ lines of different instructions
    `;
    break;
  case "lovo":
    // Another 30+ lines
    break;
  // ... more providers
}
```

### Missing Gender Field Bug

**Critical Discovery**: The gender field existed in the Voice type but was **never sent to the LLM**.

**Impact**:
- LLM couldn't make gender-aware voice selections
- Dialog format couldn't ensure male/female voice diversity
- Result: "Raed talking to himself" scenarios

**Evidence**:
```typescript
// OLD: Voice metadata sent to LLM (lines 106-134)
const voiceOptions = filteredVoices.map((voice) =>
  `${voice.name} (${voice.id})\n` +
  `  Personality: ${voice.description}\n` +
  `  Best for: ${voice.use_case}\n` +
  `  Age: ${voice.age}\n` +
  `  Accent: ${voice.accent}`
  // ‚ùå Gender field MISSING!
).join("\n\n");
```

## ElevenLabs V3 Discovery

### Why V3?

**Model Comparison**:

| Feature | V2 (eleven_multilingual_v2) | V3 (eleven_v3) |
|---------|----------------------------|----------------|
| Languages | 28 | 70+ |
| Emotional Tags | ‚ùå No | ‚úÖ Yes ([laughs], [whispers], etc.) |
| Character Limit | 500 | 3,000 |
| Speed Parameter | ‚úÖ Yes | ‚úÖ Yes (we were stripping it!) |
| Stability Values | Continuous 0-1 | Discrete: 0.0, 0.5, 1.0 |
| Expressiveness | Good | Excellent |

### V3 Dual Control System

**Innovation**: Combine baseline tone presets with inline emotional tags for rich, expressive delivery.

#### 1. Baseline Tone (description field)

Sets the overall voice character via presets:

```typescript
// Available baseline tones
cheerful | happy | excited | energetic | dynamic |
calm | gentle | soothing |
serious | professional | authoritative |
empathetic | warm |
fast_read | slow_read
```

**Example**:
```json
{
  "description": "cheerful",
  "text": "Check out our new product!"
}
```

#### 2. Emotional Tags (inline in text)

Layer emotional moments for fine-grained control:

**Available Tags**:
- **Laughter**: `[laughs]`, `[chuckles]`, `[giggles]`, `[laughs harder]`, `[starts laughing]`, `[wheezing]`
- **Vocal Effects**: `[whispers]`, `[sighs]`, `[exhales]`, `[gasps]`, `[pauses]`, `[snorts]`, `[coughs]`
- **Emotions**: `[sarcastic]`, `[excited]`, `[curious]`, `[crying]`, `[mischievously]`

**Punctuation Controls**:
- **Ellipses** (...) - Creates pauses and thoughtful delivery
- **CAPITALIZATION** - Adds emphasis to specific words

**Example**:
```json
{
  "description": "cheerful",
  "text": "[laughs] You won't believe this! Our new product... [excited] it's AMAZING! [whispers] And just between us, the price is unbeatable."
}
```

**Critical Rule**: Tags must be in **ENGLISH** regardless of target language!

### V3 Stability Constraints Discovery

**The Error**:
```json
{
  "error": {
    "status": "invalid_ttd_stability",
    "message": "Invalid TTD stability value. Must be one of: [0.0, 0.5, 1.0]"
  }
}
```

**Root Cause**: V3 changed stability from continuous (0.0-1.0) to discrete values only.

**The Fix**: Updated all 15 presets in `ElevenLabsVoiceProvider.ts`:

```typescript
// V3 preset table - stability must be 0.0, 0.5, or 1.0
const PRESETS: Record<string, Settings> = {
  // Creative (0.0): High expressiveness
  cheerful: {
    stability: 0.0,  // Changed from 0.25
    similarity_boost: 0.85,
    style: 0.5,
    speed: 1.08,
    use_speaker_boost: false,
  },

  // Natural (0.5): Balanced delivery
  neutral: {
    stability: 0.5,  // Already correct
    similarity_boost: 0.75,
    style: 0.3,
    speed: 1.0,
    use_speaker_boost: false,
  },

  // Robust (1.0): Highly stable
  calm: {
    stability: 1.0,  // Changed from 0.75
    similarity_boost: 0.65,
    style: 0.15,
    speed: 0.96,
    use_speaker_boost: false,
  },
  // ... 12 more presets
};
```

**Mapping Logic**:
- **0.0 (Creative)**: cheerful, excited, energetic, fast_read
- **0.5 (Natural)**: neutral, warm, empathetic (default)
- **1.0 (Robust)**: calm, serious, professional, slow_read

## Strategy Pattern Refactor

### The Solution

**File Structure**:
```
src/lib/prompt-strategies/
‚îú‚îÄ‚îÄ BasePromptStrategy.ts          # Abstract base with common logic
‚îú‚îÄ‚îÄ ElevenLabsV3PromptStrategy.ts  # V3 dual control system
‚îú‚îÄ‚îÄ OpenAIPromptStrategy.ts        # voiceInstructions approach
‚îú‚îÄ‚îÄ LovoPromptStrategy.ts          # Baked-in styles
‚îú‚îÄ‚îÄ QwenPromptStrategy.ts          # Direct voice control
‚îú‚îÄ‚îÄ PromptStrategyFactory.ts       # Factory pattern
‚îî‚îÄ‚îÄ index.ts                       # Barrel exports
```

### BasePromptStrategy (Abstract Base)

**File**: `src/lib/prompt-strategies/BasePromptStrategy.ts`

**Key Features**:

1. **Gender Field Fix** (lines 76-98):
```typescript
formatVoiceMetadata(voice: Voice, _context: PromptContext): string {
  let desc = `${voice.name} (id: ${voice.id})`;

  // üî• FIX: Add gender field (previously missing)
  if (voice.gender) {
    desc += `\n  Gender: ${
      voice.gender.charAt(0).toUpperCase() + voice.gender.slice(1)
    }`;
  }

  if (voice.description) {
    desc += `\n  Personality: ${voice.description}`;
  }
  if (voice.use_case) {
    desc += `\n  Best for: ${voice.use_case}`;
  }
  if (voice.age) {
    desc += `\n  Age: ${voice.age}`;
  }
  if (voice.accent && voice.accent !== "general") {
    desc += `\n  Accent: ${voice.accent}`;
  }

  return desc;
}
```

2. **Template Method Pattern**:
```typescript
abstract class BasePromptStrategy implements PromptStrategy {
  // Abstract methods - must be implemented
  abstract buildStyleInstructions(context: PromptContext): string;
  abstract buildOutputFormat(campaignFormat: CampaignFormat): string;

  // Shared implementations
  formatVoiceMetadata(voice: Voice, context: PromptContext): string { /* ... */ }
  buildFormatGuide(campaignFormat: CampaignFormat): string { /* ... */ }
  buildPrompt(context: PromptContext): PromptResult { /* ... */ }
}
```

### ElevenLabsV3PromptStrategy

**File**: `src/lib/prompt-strategies/ElevenLabsV3PromptStrategy.ts`

**Complete Style Instructions**:
```typescript
buildStyleInstructions(context: PromptContext): string {
  const { pacing } = context;

  // Build pacing guidance if specified
  let pacingGuidance = "";
  if (pacing === "fast") {
    pacingGuidance = `
üê∞ PACING REQUIREMENT: FAST-PACED DELIVERY
Create a fast-paced, energetic delivery with urgency and excitement.
RECOMMENDED baseline tones: fast_read, energetic, dynamic, excited
AVOID slow presets: calm, soothing, gentle, slow_read
Use shorter sentences and action-oriented language.
`;
  } else if (pacing === "slow") {
    pacingGuidance = `
üê¢ PACING REQUIREMENT: SLOW-PACED DELIVERY
Create a slow, deliberate delivery with thoughtful pauses.
RECOMMENDED baseline tones: slow_read, calm, gentle, soothing
AVOID fast presets: energetic, dynamic, excited, fast_read
Use longer sentences with ellipses (...) for natural pauses.
`;
  }

  return `ElevenLabs V3 Model - Dual Emotional Control System:
${pacingGuidance ? pacingGuidance : ""}

BASELINE TONE (description field):
Choose ONE baseline tone to set the overall voice character:
cheerful | happy | excited | energetic | dynamic | calm | gentle | soothing | serious | professional | authoritative | empathetic | warm | fast_read | slow_read

Include this as "description" field (REQUIRED).

EMOTIONAL TAGS (inline in text):
Available tags:
- Laughter: [laughs], [chuckles], [giggles], [laughs harder]
- Vocal effects: [whispers], [sighs], [exhales], [gasps], [pauses]
- Emotions: [sarcastic], [excited], [curious], [crying]

Punctuation controls:
- Ellipses (...) - Creates pauses
- CAPITALIZATION - Adds emphasis

Tag placement guidelines:
- Match tags to voice personality
- Tags must be in ENGLISH regardless of target language
- Don't overuse - tags should punctuate, not dominate

Example:
"description": "cheerful",
"text": "[laughs] You won't believe this! Our new product... [excited] it's AMAZING!"

Stability settings (handled automatically):
- Creative (0.0): cheerful, excited, energetic, fast_read
- Natural (0.5): neutral, warm, empathetic (default)
- Robust (1.0): calm, serious, professional, slow_read

Character limit: 3,000 characters per voice segment`;
}
```

### OpenAIPromptStrategy

**File**: `src/lib/prompt-strategies/OpenAIPromptStrategy.ts`

**Approach**: Uses `voiceInstructions` field for detailed control:

```typescript
buildStyleInstructions(context: PromptContext): string {
  const { accent, region, pacing } = context;

  let instructions = `For OpenAI TTS, provide detailed "voiceInstructions":

Voice Affect: <brief description>
Tone: <emotional tone>
Pacing: <speed - slow/moderate/fast/rapid>
Emotion: <delivery style>
Emphasis: <what to highlight>
Pronunciation: <articulation style>
Pauses: <where and how long>

Example: "Voice Affect: Energetic spokesperson; Tone: Enthusiastic; Pacing: Fast with quick delivery; Emotion: Excited; Emphasis: Strong on brand name"`;

  // Add pacing-specific guidance if specified
  if (pacing === "fast") {
    instructions += `\n\nüê∞ PACING REQUIREMENT: FAST
IMPORTANT: Include "Pacing: Rapid, energetic delivery with quick tempo"
Use short, punchy sentences with dynamic rhythm.`;
  } else if (pacing === "slow") {
    instructions += `\n\nüê¢ PACING REQUIREMENT: SLOW
IMPORTANT: Include "Pacing: Slow, deliberate delivery with thoughtful pauses"
Use longer sentences with natural pauses.`;
  }

  return instructions;
}
```

### PromptStrategyFactory

**File**: `src/lib/prompt-strategies/PromptStrategyFactory.ts`

**Factory Pattern Implementation**:
```typescript
export class PromptStrategyFactory {
  private static strategies: Record<Provider, () => PromptStrategy> = {
    elevenlabs: () => new ElevenLabsV3PromptStrategy(),
    openai: () => new OpenAIPromptStrategy(),
    lovo: () => new LovoPromptStrategy(),
    qwen: () => new QwenPromptStrategy(),
    bytedance: () => new QwenPromptStrategy(), // Reuse
    any: () => new ElevenLabsV3PromptStrategy(), // Default
  };

  static create(provider: Provider): PromptStrategy {
    const factory = this.strategies[provider];
    if (!factory) {
      throw new Error(`Unknown provider: ${provider}`);
    }
    return factory();
  }
}
```

**Usage in Generate Route**:
```typescript
// BEFORE: 230 lines of switch/case
// ...

// AFTER: 2 lines
const strategy = PromptStrategyFactory.create(provider);
const { systemPrompt, userPrompt } = strategy.buildPrompt(promptContext);
```

### Refactored Generate Route

**File**: `src/app/api/ai/generate/route.ts`

**Before**: 443 lines with 230 lines of switch/case logic
**After**: 213 lines (52% reduction)

**Key Changes**:

```typescript
// Build prompt context (lines 89-104)
const promptContext: PromptContext = {
  language,
  languageName,
  provider,
  voices: filteredVoices as Voice[],
  campaignFormat,
  duration,
  clientDescription,
  creativeBrief,
  region,
  accent,
  cta,
  dialectInstructions,
  pacing: pacing || undefined, // New: pacing control
};

// Generate prompts using strategy (lines 105-107)
const strategy = PromptStrategyFactory.create(provider);
const { systemPrompt, userPrompt } = strategy.buildPrompt(promptContext);

// Rest of LLM call logic unchanged
const response = await client.chat.completions.create({
  model,
  messages: [
    { role: "system", content: systemPrompt },
    { role: "user", content: userPrompt },
  ],
  temperature,
  // ...
});
```

## Critical Bug Fixes

### Bug 1: Speed Parameter Stripped

**Location**: `src/lib/providers/ElevenLabsVoiceProvider.ts:258-264`

**Discovery**: We tested V3 speed parameter and it **WORKS**, but we were removing it!

**Test Results** (from `/api/admin/test-v3-dialogue`):
```json
{
  "v3_fast_speed": {
    "audio_url": "https://...",
    "speed_tested": 1.15,
    "description": "SUCCESS - V3 accepts speed parameter!"
  },
  "v3_slow_speed": {
    "audio_url": "https://...",
    "speed_tested": 0.9,
    "description": "SUCCESS - V3 accepts speed parameter!"
  }
}
```

**The Fix**:
```typescript
// BEFORE (lines 258-264):
// Remove speed parameter as it's not supported in current ElevenLabs API
const apiVoiceSettings = {
  stability: voiceSettings.stability,
  similarity_boost: voiceSettings.similarity_boost,
  style: voiceSettings.style,
  use_speaker_boost: voiceSettings.use_speaker_boost,
  // speed is OMITTED! ‚ùå
};

// AFTER:
// V3 supports speed parameter (empirically validated)
const apiVoiceSettings = {
  stability: voiceSettings.stability,
  similarity_boost: voiceSettings.similarity_boost,
  style: voiceSettings.style,
  use_speaker_boost: voiceSettings.use_speaker_boost,
  speed: voiceSettings.speed, // ‚úÖ Restored!
};
```

**Impact**:
- ‚úÖ fast_read preset now works (speed: 1.15)
- ‚úÖ slow_read preset now works (speed: 0.9)
- ‚úÖ All 15 presets function as designed

### Bug 2: Missing Gender Field

**Location**: `src/lib/prompt-strategies/BasePromptStrategy.ts:76-98`

**The Fix**: Added gender to voice metadata sent to LLM.

**Impact**:
- ‚úÖ LLM can now ensure gender diversity in dialogs
- ‚úÖ "Raed talking to himself" scenarios eliminated
- ‚úÖ Better voice casting for conversation-style ads

## Pacing Control Feature

### User Experience

**UI Location**: `src/components/BriefPanel.tsx` - Row 3, next to Duration slider

**Design**:
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Duration Slider (2/3 width)         ‚îÇ
‚îÇ ‚îú‚îÄ 10s‚îÄ15s‚îÄ20s‚îÄ25s‚îÄ30s‚îÄ35s‚îÄ40s...  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Pacing Buttons (1/3 width)          ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îê                      ‚îÇ
‚îÇ ‚îÇ üê¢ ‚îÇ  ‚îÇ üê∞ ‚îÇ                      ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îò                      ‚îÇ
‚îÇ Slow    Fast                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Interaction**:
- Click üê¢ Slow ‚Üí toggles slow pacing (click again to deselect)
- Click üê∞ Fast ‚Üí toggles fast pacing (click again to deselect)
- No selection ‚Üí normal/default pacing (LLM chooses freely)
- Only one can be active at a time

### Technical Implementation

**Type System** (`src/types/index.ts`):
```typescript
export type Pacing = "slow" | "normal" | "fast";
```

**PromptContext Extension** (`src/lib/prompt-strategies/BasePromptStrategy.ts:19`):
```typescript
export interface PromptContext {
  // ... existing fields
  pacing?: Pacing; // Optional - undefined means "normal"
}
```

**Data Flow**:
```
BriefPanel State (selectedPacing)
    ‚Üì
ai-api-client.generateCreativeCopy(pacing)
    ‚Üì
/api/ai/generate (pacing in request body)
    ‚Üì
PromptContext (pacing: pacing || undefined)
    ‚Üì
Strategy.buildStyleInstructions(context)
    ‚Üì
LLM receives pacing guidance
    ‚Üì
LLM chooses appropriate preset (e.g., "fast_read")
    ‚Üì
Audio API applies speed parameter from preset
```

### Architecture: Why It's Elegant

**The Key Insight**: LLM chooses the preset, speed flows through automatically.

**Decoupled Design**:
1. **User selects pacing** ‚Üí UI state
2. **Pacing sent to LLM** ‚Üí Prompt guidance
3. **LLM chooses preset** ‚Üí "description": "energetic"
4. **Audio API applies speed** ‚Üí PRESETS["energetic"].speed = 1.12

**No Session Variables Needed**: Everything flows through the existing `description`/`style` field!

**Example Flow**:

```typescript
// User clicks üê∞ Fast
selectedPacing = "fast"

// LLM receives guidance
`
üê∞ PACING REQUIREMENT: FAST-PACED DELIVERY
RECOMMENDED baseline tones: fast_read, energetic, dynamic, excited
`

// LLM chooses preset
{
  "description": "energetic"
}

// Audio API applies preset
PRESETS["energetic"] = {
  stability: 0.0,
  speed: 1.12  // ‚Üê Fast pacing applied!
}
```

### Provider-Specific Adaptations

**ElevenLabs V3**: Uses preset recommendations + speed parameter
```typescript
if (pacing === "fast") {
  "RECOMMENDED: fast_read, energetic, dynamic"
  // ‚Üí LLM chooses ‚Üí speed=1.12 applied
}
```

**OpenAI**: Emphasizes pacing in voiceInstructions
```typescript
if (pacing === "fast") {
  "Pacing: Rapid, energetic delivery with quick tempo"
  // ‚Üí LLM includes in voiceInstructions field
}
```

**Lovo/Qwen**: General pacing guidance (limited API control)
```typescript
if (pacing === "fast") {
  "Create fast-paced delivery with shorter sentences"
  // ‚Üí LLM adjusts text content and word choice
}
```

## Testing & Validation

### V3 Test Endpoint

**File**: `src/app/api/admin/test-v3-dialogue/route.ts`

**Purpose**:
- Compare V2 vs V3 models
- Test speed parameter support
- Validate emotional tags

**Features**:
- Translates English dialogue to target language (default: Polish)
- Generates 4 audio samples:
  1. V2 baseline (no tags)
  2. V3 with emotional tags
  3. V3 with fast speed (1.15)
  4. V3 with slow speed (0.9)

**Usage**:
```bash
curl -X POST http://localhost:3000/api/admin/test-v3-dialogue \
  -H "Content-Type: application/json" \
  -d '{
    "text": "[laughs] Testing speed control!",
    "skipTranslation": true
  }'
```

**Response**:
```json
{
  "success": true,
  "results": {
    "v2_model": {
      "audio_url": "https://...",
      "model": "eleven_multilingual_v2"
    },
    "v3_model": {
      "audio_url": "https://...",
      "model": "eleven_v3"
    },
    "v3_fast_speed": {
      "audio_url": "https://...",
      "speed_tested": 1.15,
      "description": "SUCCESS!"
    },
    "v3_slow_speed": {
      "audio_url": "https://...",
      "speed_tested": 0.9,
      "description": "SUCCESS!"
    }
  }
}
```

## Impact & Benefits

### Code Quality Improvements

**Metrics**:
- ‚úÖ **52% code reduction** in generate route (443 ‚Üí 213 lines)
- ‚úÖ **Eliminated 230 lines** of switch/case chaos
- ‚úÖ **7 new strategy files** with clean separation of concerns
- ‚úÖ **Full TypeScript type safety** with proper interfaces
- ‚úÖ **Zero architectural compromises**

**Maintainability**:
- ‚úÖ Adding new providers: ~20-30 lines vs 200+ lines
- ‚úÖ Provider logic isolated and testable
- ‚úÖ Easy to understand and modify
- ‚úÖ No complex parameter threading

### Feature Capabilities

**V3 Emotional Control**:
- ‚úÖ Emotional tags ([laughs], [whispers], etc.)
- ‚úÖ Punctuation controls (ellipses, CAPS)
- ‚úÖ Baseline + tags dual control system
- ‚úÖ 3,000 character limit (6x increase from 500)

**Pacing Control**:
- ‚úÖ User-facing üê¢ Slow | üê∞ Fast toggle
- ‚úÖ LLM-driven preset selection
- ‚úÖ Automatic speed parameter application
- ‚úÖ Provider-aware implementation

**Fixed Bugs**:
- ‚úÖ Gender field now sent to LLM
- ‚úÖ Speed parameter restored for V3
- ‚úÖ All 15 presets work correctly
- ‚úÖ Stability values V3-compliant

### Business Value

**Content Quality**:
- ‚úÖ Better emotional expressiveness in ads
- ‚úÖ More authentic dialog with gender diversity
- ‚úÖ Pacing control for different campaign styles
- ‚úÖ Longer-form content support (60s ads)

**Development Velocity**:
- ‚úÖ Faster to add new providers
- ‚úÖ Easier to test provider-specific logic
- ‚úÖ Cleaner codebase for onboarding
- ‚úÖ Reduced bug surface area

**Market Expansion**:
- ‚úÖ 70+ languages with V3
- ‚úÖ Better quality for non-English markets
- ‚úÖ Emotional expressiveness across all languages
- ‚úÖ Competitive advantage in voice quality

## Files Modified

### Core Strategy Pattern (7 new files)

1. **src/lib/prompt-strategies/BasePromptStrategy.ts**
   - Abstract base class with common logic
   - Gender field fix (lines 80-84)
   - Template method pattern implementation

2. **src/lib/prompt-strategies/ElevenLabsV3PromptStrategy.ts**
   - V3 dual control system
   - Pacing guidance integration
   - Emotional tags documentation

3. **src/lib/prompt-strategies/OpenAIPromptStrategy.ts**
   - voiceInstructions approach
   - Pacing emphasis in instructions

4. **src/lib/prompt-strategies/LovoPromptStrategy.ts**
   - Baked-in styles approach
   - Style field handling

5. **src/lib/prompt-strategies/QwenPromptStrategy.ts**
   - Direct voice control
   - Minimal style instructions

6. **src/lib/prompt-strategies/PromptStrategyFactory.ts**
   - Factory pattern implementation
   - Provider strategy mapping

7. **src/lib/prompt-strategies/index.ts**
   - Barrel exports for clean imports

### Critical Fixes (2 files)

8. **src/lib/providers/ElevenLabsVoiceProvider.ts**
   - Speed parameter restored (line 264)
   - Updated comment explaining V3 support

9. **src/app/api/ai/generate/route.ts**
   - Refactored from 443 ‚Üí 213 lines
   - Strategy pattern integration
   - Pacing parameter handling

### Pacing Feature (3 files)

10. **src/types/index.ts**
    - Added Pacing type
    - Extended type system

11. **src/utils/ai-api-client.ts**
    - Added pacing parameter
    - Updated function signature

12. **src/components/BriefPanel.tsx**
    - Pacing UI controls
    - Icon buttons with tooltips

### Testing (1 file)

13. **src/app/api/admin/test-v3-dialogue/route.ts**
    - V2 vs V3 comparison
    - Speed parameter validation
    - Enhanced with speed tests

## Provider Capabilities Matrix

| Provider | Model | Emotional Control | Pacing | Speed Param | Char Limit |
|----------|-------|-------------------|--------|-------------|------------|
| **ElevenLabs V3** | eleven_v3 | Baseline + Tags | Presets + Speed | ‚úÖ Yes | 3,000 |
| **ElevenLabs V2** | eleven_multilingual_v2 | Presets only | Speed | ‚úÖ Yes | 500 |
| **OpenAI** | tts-1 | voiceInstructions | voiceInstructions | ‚ùå No | 4,096 |
| **Lovo** | Various | Baked into voice | Limited | ‚ùå No | ~500 |
| **Qwen** | qwen-tts-latest | Direct control | Limited | ‚ùå No | 512 tokens |

## Future Considerations

### Potential Enhancements

**Per-Segment Pacing**:
- Allow different pacing for different voice segments
- UI: Pacing control in ScripterPanel per segment
- Implementation: Extend VoiceTrack type with pacing field

**Emotional Tag Suggestions**:
- LLM suggests appropriate emotional tags
- UI: Preview suggested tags before generation
- Implementation: Add tag analysis to LLM prompt

**Advanced Preset Customization**:
- Allow users to create custom stability/style combinations
- UI: Advanced settings panel
- Implementation: Custom preset storage in project data

**Pacing Preview Mode**:
- Test pacing before final generation
- UI: Quick preview button with sample text
- Implementation: Lightweight TTS call with preset

### Next Architecture Step: Provider Standardization

**Current State**: Voice/music providers still use pattern-per-file approach.

**Vision**: Apply Strategy Pattern to all audio providers.

**Benefits**:
- 90% code reduction for new provider integrations
- Unified error handling and response formatting
- Easier testing with base class mocking
- Consistent API across all providers

**Estimated Impact**:
- Current: ~200 lines per new provider
- Future: ~20-30 lines per new provider
- Maintenance: Fix once, applies to all

## Lessons Learned

### What Worked Well

1. **Empirical Testing**: Creating test endpoint proved V3 capabilities
2. **Conservative Approach**: Kept presets + layered tags on top
3. **User Input**: "If you're certain they don't make sense..." ‚Üí kept presets
4. **Strategy Pattern**: Clean separation eliminated complexity
5. **Type Safety**: TypeScript caught issues early

### What We'd Do Differently

1. **Earlier Investigation**: Should have checked V3 sooner
2. **Documentation**: API docs claimed speed wasn't supported (wrong!)
3. **Testing**: Test endpoints are invaluable - create them first
4. **Architecture Reviews**: Should do regular code audits

### Key Principles Applied

1. **Single Responsibility**: Each strategy handles one provider
2. **Open/Closed**: Open for extension (new providers), closed for modification
3. **Liskov Substitution**: All strategies interchangeable via interface
4. **Dependency Inversion**: Depend on abstractions (PromptStrategy), not concrete classes
5. **Don't Repeat Yourself**: Common logic in base class

## Conclusion

The ElevenLabs V3 upgrade and Strategy Pattern refactor represents a major architectural evolution of the creative pipeline. What started as a simple question ("Which model are we using?") led to:

- **230 lines of code eliminated** through clean architecture
- **Critical bugs fixed** (gender field, speed parameter)
- **New features added** (pacing control, emotional tags)
- **System improved** (6x character limit, 70+ languages)
- **Foundation laid** for future provider integrations

The result is a maintainable, extensible system that produces higher-quality voice content while being easier to work with than before.

**Key Achievement**: Delivered both architectural cleanup AND feature improvements simultaneously, proving that refactoring doesn't have to slow down feature development - it can accelerate it.

## Voice Filtering: Region + Accent Deep Dive

_Added October 2025_

### The Problem

Region + Accent filtering wasn't working:
- Spanish + Argentinian ‚Üí Shows voices ‚úÖ
- Spanish + Latin America + Argentinian ‚Üí 0 voices ‚ùå

### Root Causes Discovered

**1. Generic vs Specific Accents**
```json
{
  "labels": {
    "accent": "latin american",  // ‚ùå Generic
    "locale": "es-AR"             // ‚úÖ Specific!
  }
}
```

**2. Type Mismatch**
```typescript
// Expected: verified_languages?: string[]
// Actual: Array of objects with locale/language/accent
```

**3. Missing Accent Filter**
When region was specified, code filtered by provider but **ignored accent parameter**.

**4. Count Mismatch**
Provider dropdown showed 26 voices (all LATAM) instead of 3 (just Argentinian).

**5. Spelling Variants**
ElevenLabs uses `"argentine"` not `"argentinian"`.

### The Fixes

**1. Extract Locale from verified_languages** (voiceProviderService.ts)
```typescript
for (const verifiedLang of voice.verified_languages) {
  let accent = verifiedLang.accent;
  if (verifiedLang.locale) {
    const [, region] = verifiedLang.locale.split('-');
    accent = region; // "AR" ‚Üí normalizeAccent ‚Üí "argentinian"
  }
}
```

**2. Apply Accent Filter in Region Query** (voice-catalogue/route.ts)
```typescript
providerVoices = regionVoices.filter(voice => {
  const matchesProvider = voice.provider === providerName;
  const matchesAccent = !accent || voice.accent === accent;
  return matchesProvider && matchesAccent;
});
```

**3. Fix Provider Counts** (voiceCatalogueService.ts)
```typescript
if (filters.region && filters.accent) {
  // Filter by BOTH region AND accent
  const regionVoices = await this.getVoicesByRegion(language, region);
  const accentVoices = regionVoices.filter(v => v.accent === accent);
  // Count per provider from filtered set
}
```

**4. Add Spelling Variant** (accents.ts)
```typescript
argentine: "argentinian", // ElevenLabs uses "argentine"
```

**5. Fix Accent Display Names** (useVoiceManagerV2.ts)
Always use API for proper formatting instead of raw capitalization.

### Impact

- ‚úÖ Region + Accent filtering works correctly
- ‚úÖ Voice counts accurate (3 not 26)
- ‚úÖ Accent display names properly formatted ("Argentinian" not "Latin_american")
- ‚úÖ All locale variants supported ("argentine", "argentinian", "AR")
- ‚úÖ Consistent behavior across all providers

### Technical Debt Paid

**Before**: Voice filtering had 3 separate bugs causing cascading failures.
**After**: Clean data flow from API ‚Üí normalization ‚Üí storage ‚Üí filtering.

## Voice Cache Rebuild: Eliminating Self-Referential HTTP

_Added October 2025_

### The Problem

Cache rebuild was **emptying the database** in production. Root cause: internal HTTP calls to own API.

```typescript
// ‚ùå BAD: Self-referential HTTP call
const response = await fetch(`${getBaseUrl()}/api/voice/list?provider=elevenlabs`);
// Network round-trip ‚Üí timeout on Vercel ‚Üí cache cleared but not repopulated
```

### The Fix

**Created** `src/services/voiceProviderService.ts` - Direct provider API calls:
- `fetchElevenLabsVoices()` - Direct ElevenLabs API
- `fetchLovoVoices()` - Direct Lovo API
- `getOpenAIVoices()` - Hardcoded (no API needed)

**Updated** `src/app/api/admin/voice-cache/route.ts`:
```typescript
// ‚úÖ GOOD: Direct external API call
const elevenlabsVoices = await fetchElevenLabsVoices();
// One network hop, reliable, no self-dependency
```

### Impact

- ‚úÖ Rebuild works reliably in production
- ‚úÖ No more empty database on deploy
- ‚úÖ Faster rebuild (eliminated double network hop)
- ‚úÖ Cleaner architecture (shared service)

## Pronunciation Dictionary Updates: Remove-and-Add Pattern

_Added October 2025_

### The Problem

Saving pronunciation rules created new dictionaries every time, accumulating orphans in ElevenLabs.

### The Fix

**Architecture**: ElevenLabs API doesn't support DELETE or return rules via GET, only metadata. Solution uses `remove-rules` + `add-rules` pattern:

- **POST** `/api/pronunciation` ‚Üí Create first dictionary, store ID in Redis
- **PATCH** `/api/pronunciation/{id}` ‚Üí Remove all old rules + add new rules (update-in-place)
- **DELETE** `/api/pronunciation/{id}` ‚Üí Remove all rules + clear Redis

**Redis role**: Authoritative source for rules (ElevenLabs only stores for TTS, doesn't return them).

**Files**: `elevenlabs-pronunciation.ts` (added `removeRules`/`addRules`), `pronunciation/[id]/route.ts` (added PATCH), `PronunciationEditor.tsx` (uses PATCH for updates).

### Impact

- ‚úÖ Single global dictionary maintained across saves
- ‚úÖ No orphaned dictionaries
- ‚úÖ Proper separation: Redis = source of truth, ElevenLabs = TTS-time only

## Per-Track Provider Switching & Speed Control Redux

_January 2025_

### The Business Problem

**Use Case**: Pharmaceutical-style advertisements require:
- **Main content**: Natural, humane-sounding voice (ElevenLabs excels here)
- **Disclaimer section**: Ultra-fast legal text (OpenAI supports up to 4.0x speed)
- **Constraint**: Must fit within 30-second Spotify ad duration

**Challenge**: System was mono-provider per script - couldn't mix ElevenLabs quality with OpenAI speed capabilities.

### The Investigation: Speed Parameter Deep Dive

#### Discovery: ElevenLabs V3 Speed Limitations

**Test Setup**: Two identical scripts with same voice, different speeds (0.7x and 1.2x)

**Expected**: ~70% duration difference (1.2/0.7 ‚âà 1.71x faster)

**Actual Results**:
```json
{
  "track_1_speed_1.2x": { "duration": 6.269 },
  "track_2_speed_0.7x": { "duration": 6.426 }
}
// Difference: 0.157s (2.5% variance) = normal generation noise, NOT speed change!
```

**Conclusion**: ElevenLabs speed parameter is being sent correctly but has no effect for extreme values.

**Root Cause**: Documentation research revealed ElevenLabs V3 **only accepts 0.7-1.2x range**.

**Evidence from API logs**:
```typescript
üì° === FINAL REQUEST TO ELEVENLABS API ===
{
  "voice_settings": {
    "speed": 1.5  // ‚ùå Outside valid range, silently ignored!
  }
}
‚úÖ ElevenLabs API response status: 200  // No error, just ignores the value
```

#### Discovery: OpenAI Speed Range Error

**Documentation Check**: OpenAI TTS API spec states speed range is **0.25 to 4.0**.

**Our Implementation**: Was incorrectly limited to 1.0-4.0x (missing slow-motion capability).

**Impact**: Users couldn't slow down OpenAI voices below normal speed.

### The Architecture Solution: Per-Track Provider Override

#### Type System Extensions

**File**: `src/types/index.ts`

**Added Fields**:
```typescript
export type Voice = {
  id: string;
  name: string;
  provider?: Provider; // NEW: Voice provider for API routing
  // ... existing fields
};

export type VoiceTrack = {
  voice: Voice | null;
  text: string;
  trackProvider?: Provider; // NEW: Override global provider for this track
  speed?: number; // Updated comment: OpenAI: 0.25-4.0, ElevenLabs: 0.7-1.2
  // ... existing fields
};
```

**Purpose**: Enable track-level provider selection while maintaining global provider as default.

#### UI: Provider Selection in Settings Modal

**File**: `src/components/ui/VoiceInstructionsDialog.tsx`

**Changes**:
1. **Added provider dropdown** at top of modal
2. **Provider-aware speed ranges**: Dynamically adjusts slider min/max based on selected provider
3. **Warning when switching**: Shows "‚ö†Ô∏è Changing provider will require selecting a new voice"
4. **Speed reset on provider change**: Automatically adjusts to new provider's default

**Interface Update**:
```typescript
interface VoiceInstructionsDialogProps {
  provider: Provider;           // Global provider
  trackProvider?: Provider;     // Track-specific override
  onSave: (
    instructions: string,
    speed: number | undefined,
    provider: Provider          // NEW: Returns selected provider
  ) => void;
}
```

**Provider Selection Logic**:
```typescript
const [providerValue, setProviderValue] = useState<Provider>(
  trackProvider || provider  // Use track override or fall back to global
);

const handleProviderChange = (newProvider: Provider) => {
  setProviderValue(newProvider);
  setSpeedValue(getDefaultSpeed(newProvider)); // Reset speed for new provider
};
```

#### Voice Loading: Parallel Provider Fetching

**File**: `src/components/ScripterPanel.tsx`

**Problem**: Previously loaded voices only for the globally selected provider.

**Solution**: Load voices for BOTH ElevenLabs and OpenAI in parallel:

```typescript
const [elevenLabsVoices, setElevenLabsVoices] = useState<Voice[]>([]);
const [openAIVoices, setOpenAIVoices] = useState<Voice[]>([]);

// Load both providers in parallel
useEffect(() => {
  const loadAllVoices = async () => {
    const [elevenLabsData, openAIData] = await Promise.all([
      loadVoicesForProvider('elevenlabs'),
      loadVoicesForProvider('openai'),
    ]);

    // Ensure each voice has provider field set
    setElevenLabsVoices(elevenLabsData.map(v => ({ ...v, provider: 'elevenlabs' })));
    setOpenAIVoices(openAIData.map(v => ({ ...v, provider: 'openai' })));
  };

  loadAllVoices();
}, [selectedLanguage, selectedRegion, selectedAccent, campaignFormat]);
```

**Voice Picker Logic**:
```typescript
// Helper function to get voices for specific track
const getVoicesForTrack = (trackProvider?: Provider): Voice[] => {
  const provider = trackProvider || selectedProvider;
  const rawVoices = overrideVoices || (
    provider === 'openai' ? openAIVoices : elevenLabsVoices
  );
  // Apply deduplication...
  return dedupedVoices;
};

// In render:
<VoiceCombobox
  label={track.trackProvider ? `Voice (${track.trackProvider === 'openai' ? 'OpenAI' : 'ElevenLabs'})` : "Voice"}
  voices={getVoicesForTrack(track.trackProvider)}
/>
```

#### API Routing: Provider Resolution Cascade

**File**: `src/services/audioService.ts`

**Problem**: Previously used global `selectedProvider` for all tracks.

**Solution**: Three-level provider resolution:

```typescript
for (const track of voiceTracks) {
  // Priority: 1. Track override, 2. Voice provider, 3. Global default
  const trackProvider = track.trackProvider || track.voice.provider || selectedProvider;

  console.log(`üé≠ Sending to ${trackProvider}:`);
  console.log(`  - Provider: ${trackProvider}${track.trackProvider ? ' (track override)' : ''}`);

  // Route to provider-specific API
  const res = await fetch(`/api/voice/${trackProvider}-v2`, {
    // ... request body
  });
}
```

**Provider Field Population**:
Critical fix - voices loaded from API didn't have `provider` field, causing routing failures.

```typescript
// In loadVoicesForProvider:
return voices.map((v: Voice) => ({ ...v, provider }));
// Ensures voice.provider is always set for correct API routing
```

### Speed Range Corrections

#### ElevenLabs: Constrained to API Limits

**File**: `src/lib/voice-presets.ts`

**Change**:
```typescript
case "elevenlabs":
  // BEFORE: { min: 0.5, max: 1.5 }
  // AFTER:
  return { min: 0.7, max: 1.2 };  // V3 API valid range
```

**Rationale**: Values outside 0.7-1.2 are silently ignored by ElevenLabs V3 API.

**All Presets Already Compliant**: Existing preset speeds (0.9-1.15) were already within valid range.

#### OpenAI: Corrected to Full API Range

**File**: `src/lib/voice-presets.ts`

**Change**:
```typescript
case "openai":
  // BEFORE: { min: 1.0, max: 4.0 }
  // AFTER:
  return { min: 0.25, max: 4.0 };  // Official OpenAI API spec
```

**Rationale**: OpenAI supports slow-motion playback (0.25x-1.0x) that was previously unavailable.

**UI Simplification**: Removed preset speed buttons (Normal, Fast, Very Fast) - users have full slider control.

### Enhanced Logging for Debugging

**Files Modified**:
- `src/services/audioService.ts`
- `src/lib/providers/ElevenLabsVoiceProvider.ts`

**audioService.ts Additions**:
```typescript
console.log(`  - Speed: ${track.speed !== undefined ? `${track.speed}x (manual)` : 'not set (using preset/default)'}`);
console.log(`  - Provider: ${trackProvider}${track.trackProvider ? ' (track override)' : ''}`);
```

**ElevenLabsVoiceProvider.ts Enhancements**:
```typescript
console.log(`  Speed parameter received: ${speed !== undefined ? `${speed}x` : 'undefined (will use preset)'}`);

console.log(`  üéõÔ∏è Speed calculation:`);
console.log(`    - Preset speed (from voice tone): ${presetSpeed}x`);
console.log(`    - Manual speed override: ${speed !== undefined ? `${speed}x` : 'none'}`);
console.log(`    - Effective speed (FINAL): ${effectiveSpeed}x`);

console.log(`\n  üì° === FINAL REQUEST TO ELEVENLABS API ===`);
console.log(`  Request body:`, JSON.stringify(requestBody, null, 2));
console.log(`  === END REQUEST ===\n`);

console.log(`  ‚úÖ ElevenLabs API response status: ${response.status}`);
console.log(`  üìã Response headers:`, {
  'content-type': response.headers.get('content-type'),
  'content-length': response.headers.get('content-length'),
});
```

**Purpose**: Full visibility into speed parameter flow from UI ‚Üí storage ‚Üí API ‚Üí response.

### User Workflow: Pharma Ad Example

**Scenario**: 30-second Spotify ad with fast disclaimer

**Steps**:

1. **Create main voice track** (Track 1):
   - Voice: ElevenLabs "Vale - Amigable" (Chilean accent, humane sound)
   - Script: "¬°Oye, viste al Nico? Lleg√≥ con una Coca-Cola bien helaita..."
   - Speed: 1.0x (normal, natural pacing)
   - Provider: ElevenLabs (default)

2. **Create disclaimer track** (Track 2):
   - Click gear icon on Track 2
   - Change provider dropdown to "OpenAI"
   - Voice picker now shows OpenAI voices (Echo, Alloy, Fable, etc.)
   - Select OpenAI voice suitable for rapid speech
   - Script: "Terms and conditions apply. See website for details..."
   - Speed: 2.5x (ultra-fast legal disclaimer)
   - Provider: OpenAI (track override)

3. **Generate**:
   - Track 1 ‚Üí `/api/voice/elevenlabs-v2` (natural quality)
   - Track 2 ‚Üí `/api/voice/openai-v2` (crystal meth speed)
   - Mixer combines both tracks
   - Total duration fits in 30 seconds

**Result**: Best of both worlds - ElevenLabs quality + OpenAI speed capability.

### Implementation Files

**Type Definitions** (1 file):
- `src/types/index.ts`: Added `trackProvider` to VoiceTrack, `provider` to Voice

**UI Components** (2 files):
- `src/components/ui/VoiceInstructionsDialog.tsx`: Provider dropdown, provider-aware speed controls
- `src/components/ScripterPanel.tsx`: Parallel voice loading, track-specific voice filtering

**Services** (1 file):
- `src/services/audioService.ts`: Provider resolution cascade, routing logic

**Configuration** (1 file):
- `src/lib/voice-presets.ts`: Corrected speed ranges for both providers

**Logging** (2 files):
- `src/services/audioService.ts`: Track provider logging
- `src/lib/providers/ElevenLabsVoiceProvider.ts`: Comprehensive request/response logging

### Technical Challenges Solved

#### Challenge 1: Provider Field Hoisting

**Problem**: Voices loaded from API lacked `provider` field, breaking routing logic.

**Solution**: Map over loaded voices to ensure `provider` field is always present:
```typescript
return voices.map((v: Voice) => ({ ...v, provider }));
```

**Impact**: Eliminated 404 errors when switching providers (e.g., OpenAI voice "echo" being sent to ElevenLabs API).

#### Challenge 2: React Hooks Violation

**Problem**: Initially tried to use `useMemo` inside `voiceTracks.map()` callback:
```typescript
voices={useMemo(() => getVoicesForTrack(...), [...])}
// ‚ùå ERROR: React Hook "useMemo" cannot be called inside a callback
```

**Solution**: Extracted to helper function callable in render:
```typescript
const getVoicesForTrack = (trackProvider?: Provider): Voice[] => {
  // Filtering logic here
};

// In render:
voices={getVoicesForTrack(track.trackProvider)}  // ‚úÖ Works!
```

#### Challenge 3: Build Warnings

**Fixed**:
- Unused `useMemo` import in ScripterPanel
- Unused `voiceTrackCount` parameter in SoundFxPanel
- Missing hook dependencies in admin pages
- Removed unused variables (`GlassyOptionPicker`, `campaignFormatOptions`, `getProviderLabel`)

**Result**: Clean build with zero errors/warnings.

### Performance Considerations

**Voice Loading**: Parallel fetching reduces load time:
```typescript
// Sequential: ~2 seconds (1s per provider)
await loadVoicesForProvider('elevenlabs');
await loadVoicesForProvider('openai');

// Parallel: ~1 second (both fetch simultaneously)
await Promise.all([
  loadVoicesForProvider('elevenlabs'),
  loadVoicesForProvider('openai'),
]);
```

**Memory**: Minimal overhead - ~200 voices √ó 2 providers = ~400 voice objects in state (negligible).

**Caching**: Voice lists cached by language/region/accent combination, not duplicated per provider.

### Speed Parameter Validation Matrix

| Provider | Valid Range | UI Range | Behavior Outside Range |
|----------|-------------|----------|------------------------|
| ElevenLabs V3 | 0.7 - 1.2 | 0.7 - 1.2 | Silently ignored/clamped by API |
| OpenAI | 0.25 - 4.0 | 0.25 - 4.0 | API accepts, applies correctly |
| Lovo | N/A | N/A | Speed parameter not supported |

**Testing Methodology**:
1. Set two tracks with same text/voice to extreme speeds (0.7x, 1.2x for ElevenLabs)
2. Generate audio and measure actual durations
3. Compare expected vs actual duration ratio
4. If ratio matches speed ratio ‚Üí working; if ratio ‚âà1.0 ‚Üí not working

### Impact & Benefits

**Business Value**:
- ‚úÖ **Pharma-ad use case enabled**: Mix quality (ElevenLabs) with speed (OpenAI)
- ‚úÖ **30-second constraint met**: Ultra-fast disclaimers fit legal text in time limit
- ‚úÖ **Flexibility**: Any track can use any provider based on requirements

**Code Quality**:
- ‚úÖ **Type-safe provider routing**: TypeScript ensures correct API calls
- ‚úÖ **Parallel voice loading**: ~50% faster voice picker population
- ‚úÖ **Clean architecture**: Provider resolution cascade is explicit and debuggable
- ‚úÖ **Zero build warnings**: Fixed all React hooks and unused variable issues

**User Experience**:
- ‚úÖ **Intuitive UI**: Provider selection in same modal as other voice settings
- ‚úÖ **Visual feedback**: Voice picker label shows provider when overridden
- ‚úÖ **Clear warnings**: Notifies user when provider change requires new voice selection
- ‚úÖ **No confusion**: Speed ranges automatically adjust to provider capabilities

### Lessons Learned

**API Documentation Trust**:
- ‚úÖ Always empirically test claims (speed parameter "worked" but was limited)
- ‚úÖ Documentation can be incomplete or outdated
- ‚úÖ Comprehensive logging is essential for debugging silent failures

**Architecture Wins**:
- ‚úÖ Voice object already had `provider` field in the design (prescient!)
- ‚úÖ Provider-specific logic already isolated in Strategy Pattern
- ‚úÖ Adding per-track override was clean ~200 lines, not a massive refactor

**Testing Approach**:
- ‚úÖ Duration comparison is definitive proof of speed parameter effectiveness
- ‚úÖ Console logging full request/response bodies catches API mismatches
- ‚úÖ Real-world use cases (pharma ad) drive feature priorities

### Future Enhancements

**Potential Additions**:

1. **Quick Provider Switch**:
   - "‚ö° Use OpenAI for speed" button next to voice picker
   - Auto-selects similar OpenAI voice based on ElevenLabs voice characteristics

2. **Speed Presets by Use Case**:
   - "Pharma Disclaimer": 2.5x OpenAI
   - "Promo Intro": 1.2x ElevenLabs
   - "Narration": 0.95x ElevenLabs

3. **Provider Recommendation**:
   - UI suggests provider based on detected text content
   - Legal keywords ‚Üí recommend OpenAI with high speed
   - Emotional content ‚Üí recommend ElevenLabs with tags

4. **Mixed-Provider Templates**:
   - Pre-configured track layouts for common patterns
   - "Pharma Ad": 2 tracks (ElevenLabs + OpenAI)
   - "Contest Rules": 1 main + 1 fast disclaimer

### Conclusion

The per-track provider switching feature represents a pragmatic solution to a real business constraint (30-second ad limit with mandatory legal text). By enabling track-level provider selection, we unlock:

- **Quality where it matters** (ElevenLabs for main content)
- **Speed where needed** (OpenAI for disclaimers)
- **Flexibility for future use cases** (any track can use any provider)

What started as a speed parameter investigation ("why doesn't ElevenLabs speed work?") evolved into a comprehensive feature that fundamentally expands system capabilities while maintaining clean architecture and type safety.

**Key Achievement**: Delivered a complex feature (mixed-provider scripts) while simultaneously fixing bugs (speed ranges, provider routing) and improving code quality (build warnings, logging) - proving that feature work and technical debt can be addressed together when architecture is sound.

## Smart Speed Post-Processing

_January 2025_

**Feature**: Client-side audio time-stretching with independent pitch control for ElevenLabs voices.

**Purpose**: Enable natural-sounding speedup (1.0-1.6x) for pharma disclaimers and other use cases requiring compressed timing without quality degradation.

### The Problem

Even with per-track provider switching (ElevenLabs for quality + OpenAI for speed), users wanted ElevenLabs-quality voices at speeds beyond the native 1.2x limit. Speeding up audio naturally raises pitch (chipmunk effect), requiring sophisticated pitch compensation.

### The Solution

**Client-Side Post-Processing Pipeline**:
```
Generate ‚Üí Download ‚Üí applyTimeStretch(tempo, pitch) ‚Üí Re-upload ‚Üí Mixer
```

**Technology**: soundtouchjs (WSOLA algorithm)
- Real-time capable on all devices
- Optimized for speech at 1.0-1.6x range
- Manual pitch compensation (0.7x-1.2x)

### Key Features

**Dual Slider Control**:
- **Tempo**: 1.0-1.6x (0.01 step granularity)
- **Pitch**: 0.7-1.2x (0.01 step granularity)
- **Tabbed UI**: Smart Speed | Fit Duration | Advanced

**Typical Values**:
- 1.1x tempo ‚Üí 0.95x pitch
- 1.3x tempo ‚Üí 0.85-0.90x pitch
- 1.5x tempo ‚Üí 0.75-0.80x pitch

**Alternative Libraries Researched**:
- Rubber Band WASM: Superior quality but ~10x CPU (overkill for browser)
- Professional DAWs (Elastique, ZTX): Not available for web
- Superpowered SDK: Commercial option (potential future upgrade)
- Verdict: soundtouchjs is correct choice for speech at these speeds

### Implementation

**Files Modified**:
- `src/types/index.ts`: Added postProcessingSpeedup/Pitch to VoiceTrack
- `src/utils/audio-processing.ts`: Core applyTimeStretch() function
- `src/services/audioService.ts`: Post-processing pipeline integration
- `src/components/ui/VoiceInstructionsDialog.tsx`: Dual slider UI
- `src/app/api/voice/upload-processed/route.ts`: New upload endpoint

**Bug Fixes**:
- Corrected soundtouchjs API usage (WebAudioBufferSource + extract())
- Fixed buffer overflow with smaller chunk sizes
- Narrowed pitch range based on user testing (0.8‚Üí0.7x min)

### Impact

- ‚úÖ **Business Value**: Enables pharma disclaimers at 1.5x+ while maintaining ElevenLabs quality
- ‚úÖ **User Experience**: Fine-grained control (0.01 step sliders) for precise tuning
- ‚úÖ **Performance**: Real-time processing, mobile-capable
- ‚úÖ **Architecture**: Clean double-upload trade-off for client-side simplicity

**Documentation**: See [Smart Speed Guide](./smart-speed.md) for complete technical details, troubleshooting, and alternative libraries analysis.

## Multiple SoundFX Support

_November 2025_

### The Problem

Users could only add one sound effect per project. Creative ads often require multiple effects (e.g., intro horn + door slam + background ambience).

### The Implementation

**Architecture**: Array-based soundfx management following voice tracks pattern.

**Files Modified**:
- `src/types/index.ts`: SoundFxPrompt already supported placement intent
- `src/hooks/useFormManager.ts`: Added soundFxPrompts array, CRUD operations
- `src/components/SoundFxPanel.tsx`: Transformed to render multiple form cards
- `src/app/project/[id]/page.tsx`: Loop through array for generation
- `src/services/audioService.ts`: Moved clearTracks outside loop

**Key Decisions**:
1. **Single generate button** (not per-form): Simpler UX, cache handles unchanged prompts
2. **Placement per soundfx**: Each effect has independent placement (start/after voice X/end)
3. **Partial updates**: `updateSoundFxPrompt(index, updates)` merges instead of replacing
4. **Sequential generation**: Generate soundfx one by one to avoid race conditions

### Bugs Fixed

**Bug 1: Lost form data on placement change**
- **Cause**: `updateSoundFxPrompt` replaced entire object instead of merging
- **Fix**: Changed to `{...existing, ...updates}` spread pattern

**Bug 2: Only last soundfx appeared on timeline**
- **Cause**: `clearTracks("soundfx")` called inside generation loop
- **Fix**: Moved to before loop (clear once, then append all)

**Bug 3: TypeScript signature mismatch**
- **Cause**: Interface declared `prompt: SoundFxPrompt`, implementation used `Partial<SoundFxPrompt>`
- **Fix**: Updated interface to match implementation

### Caching Behavior

ElevenLabs soundfx API includes full cache support (lines 56-78 in `ElevenLabsSoundFxProvider.ts`):
- Cache key: `generateCacheKey(text, {duration, provider})`
- Cache hit: Returns existing blob URL, no API call
- Cache miss: Generates new audio, uploads to Vercel blob

When regenerating multiple soundfx, unchanged prompts serve from cache automatically.

### Impact

**User workflow**:
- Add multiple soundfx forms via "+ Add Sound Effect" button
- Configure each with independent prompt/placement/duration
- Generate all with single button (cached prompts reuse existing audio)
- Mixer displays all tracks with correct positioning

**Persistence**: Both prompts and generated URLs stored in Redis, restored on reload.

---

**Related Documentation**:
- [Architecture Overview](./architecture.md) - Main system architecture
- [Pronunciation System](./pronounciation.md) - ElevenLabs pronunciation dictionaries
- [Voice System Guide](./voice-system-guide.md) - Redis voice management
- [Smart Speed Guide](./smart-speed.md) - Post-processing audio time-stretching
